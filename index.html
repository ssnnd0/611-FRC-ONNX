<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raspberry Pi Machine Learning Vision for FRC</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: black;
            color: white;
            /* cursor: none;  Remove this line to show the default cursor */ 
            z-index: 999;
        }
        .custom-cursor {
            position: absolute;
            width: 10px;
            height: 10px;
            background-color: white;
            border-radius: 50%;
            pointer-events: none;
            z-index: 1000;
        }
        .logo {
            display: block;
            margin: 0 auto;
            width: 150px;
        }
        footer {
            text-align: center;
            margin-top: 20px;
            font-size: 0.8em;
        }
        canvas {
            display: block;
            position: absolute;
            top: 0;
            left: 0;
            height:100%;
            width:100%;
            z-index:-1;
        }
    </style>
</head>
<body>
    <div class="custom-cursor" id="customCursor"></div> 
    <canvas id="backgroundCanvas"></canvas>
    <img src="team611.png" alt="Team 611 FRC Logo" class="logo">
    <h1>Raspberry Pi Machine Learning Vision for FRC</h1>
    <h2>Inspiration</h2>
    <p>Vision tracking for FRC (FIRST Robotics Competition).</p>
    <h2>What does it do?</h2>
    <p>CustomVision.AI exports to Tensorflow and Onnx, which is used within the program to detect the object itself, then the Python program runs vision math on the supplied co-ordinates of any detected object to find out where it is in space. The program detects the object, and runs vision calculations to find distance to the object. It sends this information over the robot network using PyNetworkTables for additional processing on the roboRIO (e.g; pathfinding).</p>
    <h2>Next Steps</h2>
    <p>We can optimize our machine learning model by ditching CustomVision.AI and Tensorflow entirely and instead running the model on an OpenCV Dynamic Neural Network, and using all four cores on the Raspberry Pi. With this change, the vision program will be able to run in complete realtimeâ€”opening its use for on-the-fly pathfinding in the autonomous period and lining up with targets during the teleoperated period. Additionally, weâ€™d love to extract 3D-world co-ordinates from the detected object using OpenCV, allowing us to go from driving straight with PID loops to generating paths on the fly with Pathfinder to get our robot to swerve directly to its target.</p>
    <h3>Want to learn more?</h3>
    <ul>
        <li><a href="https://docs.google.com/document/d/1xEkql4t2k2on5pWODVsJKmNB83CbAXsfhYoOYy8iIx8/edit?usp=sharing">Google Doc using Tensorflow</a></li>
        <li><a href="https://docs.google.com/document/d/1wLhM5ahvdox7a_Fom5_leUtu3d5cdZXE6BZQBcUypsc/edit?usp=sharing">Google Doc using ONNX</a></li>
    </ul>
    <h2>ðŸ”’ Code License</h2>
    <p>This repository is licensed through the <code>The Unlicense</code>. More details are listed <a href="https://github.com/ssnnd0/611-FRC-VISIOn/blob/main/LICENSE">here</a>.</p>
    <pre>
        <code>
            This is free and unencumbered software released into the public domain.
            Anyone is free to copy, modify, publish, use, compile, sell, or
            distribute this software, either in source code form or as a compiled
            binary, for any purpose, commercial or non-commercial, and by any
            means.
            In jurisdictions that recognize copyright laws, the author or authors
            of this software dedicate any and all copyright interest in the
            software to the public domain. We make this dedication for the benefit
            of the public at large and to the detriment of our heirs and
            successors. We intend this dedication to be an overt act of
            relinquishment in perpetuity of all present and future rights to this
            software under copyright law.
            THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
            EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
            MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
            IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR
            OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
            ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
            OTHER DEALINGS IN THE SOFTWARE.
            For more information, please refer to https://unlicense.org
        </code>
    </pre>
    <h3>Documentation</h3>
    <ul>
        <li><a href="https://onnx.ai/">ONNX Documentation</a></li>
        <li><a href="https://www.tensorflow.org/">TensorFlow Documentation</a></li>
    </ul>
    <footer>
        Â© Sandro Thornton / https://github.com/ssnnd0
    </footer>
    <script>
        const canvas = document.getElementById('backgroundCanvas');
        const ctx = canvas.getContext('2d');
        const dots = [];
        const numDots = 75;
        const maxDistance = 150;

        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        for (let i = 0; i < numDots; i++) {
            dots.push({
                x: Math.random() * canvas.width,
                y: Math.random() * canvas.height,
                vx: (Math.random() - 0.5) * 2,
                vy: (Math.random() - 0.5) * 2
            });
        }

        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            dots.forEach(dot => {
                dot.x += dot.vx;
                dot.y += dot.vy;

                if (dot.x < 0 || dot.x > canvas.width) dot.vx *= -1;
                if (dot.y < 0 || dot.y > canvas.height) dot.vy *= -1;

                ctx.beginPath();
                ctx.arc(dot.x, dot.y, 2, 0, Math.PI * 2);
                ctx.fillStyle = 'white';
                ctx.fill();
            });

            for (let i = 0; i < dots.length; i++) {
                for (let j = i + 1; j < dots.length; j++) {
                    const dx = dots[i].x - dots[j].x;
                    const dy = dots[i].y - dots[j].y;
                    const distance = Math.sqrt(dx * dx + dy * dy);

                    if (distance < maxDistance) {
                        ctx.beginPath();
                        ctx.moveTo(dots[i].x, dots[i].y);
                        ctx.lineTo(dots[j].x, dots[j].y);
                        ctx.strokeStyle = 'rgba(0, 255, 0, ' + (1 - distance / maxDistance) + ')';
                        ctx.stroke();
                    }
                }
            }

            requestAnimationFrame(draw);
        }

        // Remove the mousemove event listener 
        // document.addEventListener('mousemove', function(e) { ... });

        draw();
    </script>
</body>
</html>
