<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FRC 611 VISION</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: black;
            color: white;
            /* Remove cursor: none to show the default cursor */
            margin: 0; /* Remove default body margins */
        }
        .custom-cursor {
            display: none; /* Hide the custom cursor */
        }
        .logo {
            display: block;
            margin: 20px auto; /* Add some top margin */
            width: 150px;
        }
        footer {
            text-align: center;
            margin-top: 20px;
            font-size: 0.8em;
            position: relative; /* Position footer relative to body */
            z-index: 1; /* Ensure footer is above canvas */
        }
        canvas {
            display: block;
            position: fixed; /* Make canvas fixed to the viewport */
            top: 0;
            left: 0;
            width: 100vw; /* 100% of viewport width */
            height: 100vh; /* 100% of viewport height */
            z-index: -1; /* Ensure canvas is behind content */
        }
    </style>
</head>
<body>
    <div class="custom-cursor" id="customCursor"></div>
    <canvas id="backgroundCanvas"></canvas>
    <img src="team611.png" alt="Team 611 FRC Logo" class="logo">
    <h1>Raspberry Pi Machine Learning Vision for FRC</h1>
    <h2>Inspiration</h2>
    <p>Vision tracking for FRC (FIRST Robotics Competition).</p>
    <h2>What does it do?</h2>
    <p>CustomVision.AI exports to Tensorflow and Onnx, which is used within the program to detect the object itself, then the Python program runs vision math on the supplied co-ordinates of any detected object to find out where it is in space. The program detects the object, and runs vision calculations to find distance to the object. It sends this information over the robot network using PyNetworkTables for additional processing on the roboRIO (e.g; pathfinding).</p>
    <h2>Next Steps</h2>
    <p>We can optimize our machine learning model by ditching CustomVision.AI and Tensorflow entirely and instead running the model on an OpenCV Dynamic Neural Network, and using all four cores on the Raspberry Pi. With this change, the vision program will be able to run in complete realtimeâ€”opening its use for on-the-fly pathfinding in the autonomous period and lining up with targets during the teleoperated period. Additionally, weâ€™d love to extract 3D-world co-ordinates from the detected object using OpenCV, allowing us to go from driving straight with PID loops to generating paths on the fly with Pathfinder to get our robot to swerve directly to its target.</p>
    <h3>Want to learn more?</h3>
    <ul>
        <li><a href="https://docs.google.com/document/d/1xEkql4t2k2on5pWODVsJKmNB83CbAXsfhYoOYy8iIx8/edit?usp=sharing">Google Doc using Tensorflow</a></li>
        <li><a href="https://docs.google.com/document/d/1wLhM5ahvdox7a_Fom5_leUtu3d5cdZXE6BZQBcUypsc/edit?usp=sharing">Google Doc using ONNX</a></li>
    </ul>
    <h2>ðŸ”’ Code License</h2>
    <p>This repository is licensed through the <code>The Unlicense</code>. More details are listed <a href="https://github.com/ssnnd0/611-FRC-VISIOn/blob/main/LICENSE">here</a>.</p>
    <pre>
        <code>
            This is free and unencumbered software released into the public domain.
            Anyone is free to copy, modify, publish, use, compile, sell, or
            distribute this software, either in source code form or as a compiled
            binary, for any purpose, commercial or non-commercial, and by any
            means.
        </code>
    </pre>
    <h3>Documentation</h3>
    <ul>
        <li><a href="https://onnx.ai/">ONNX Documentation</a></li>
        <li><a href="https://www.tensorflow.org/">TensorFlow Documentation</a></li>
    </ul>
    <footer>
        Â© Sandro Thornton / https://github.com/ssnnd0
    </footer>
    <script>
        const canvas = document.getElementById('backgroundCanvas');
        const ctx = canvas.getContext('2d');
        const dots = [];
        const numDots = 200;
        const maxDistance = 150;

        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        for (let i = 0; i < numDots; i++) {
            dots.push({
                x: Math.random() * canvas.width,
                y: Math.random() * canvas.height,
                vx: (Math.random() - 0.5) * 2,
                vy: (Math.random() - 0.5) * 2
            });
        }

        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            dots.forEach(dot => {
                dot.x += dot.vx;
                dot.y += dot.vy;

                if (dot.x < 0 || dot.x > canvas.width) dot.vx *= -1;
                if (dot.y < 0 || dot.y > canvas.height) dot.vy *= -1;

                ctx.beginPath();
                ctx.arc(dot.x, dot.y, 2, 0, Math.PI * 2);
                ctx.fillStyle = 'white';
                ctx.fill();
            });

            for (let i = 0; i < dots.length; i++) {
                for (let j = i + 1; j < dots.length; j++) {
                    const dx = dots[i].x - dots[j].x;
                    const dy = dots[i].y - dots[j].y;
                    const distance = Math.sqrt(dx * dx + dy * dy);

                    if (distance < maxDistance) {
                        ctx.beginPath();
                        ctx.moveTo(dots[i].x, dots[i].y);
                        ctx.lineTo(dots[j].x, dots[j].y);
                        ctx.strokeStyle = 'rgba(40, 140, 255, ' + (1 - distance / maxDistance) + ')';
                        ctx.stroke();
                    }
                }
            }

            requestAnimationFrame(draw);
        }

        draw(); // Start the animation

        // Resize the canvas when the window is resized
        window.addEventListener('resize', () => {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        });
    </script>
</body>
</html>
